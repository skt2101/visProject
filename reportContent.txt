Most Predictable League : 

In data science predictibility is measured by entropy, which determines the amount of change in an entity.
We have used a similar measure to determine the predictibility of various soccer leagues across Europe.For this purpose,
first we have merged the countries and the leagues table in the dataset together. Then we went through all the matches and 
removed any matches which were played outside of the available leagues and had any incomplete data or 'Nan' values.
    mergedLeagueCountry = generateMergedLeagueCountryData(countryId,countries,leagues)
    filteredMatches = getFilteredMatches(matches, mergedLeagueCountry)
    # get only those matches that were played in the leagues defined in the database.
    filteredMatches = utils.removeNan(filteredMatches)
    # drop any matches with Nan values in them.
Then for each of the matches obtained in the previous step , we have found out the entropy of the match by taking into account the winning chances
given by 3 different betting sites. Then we used the scipy.stats.entropy function to calculate the entropy for each match.

matchEntropies = list(map(utils.calculateEntropy,filteredMatches)) 
where utils.calculateEntropy is the function to calculate the entropy of a match passed as argument.

Then we found out the entropy of each of the leagues across all of the available seasons by taking the mean of the matches played
in that league for every season. This gave us a single entropy value for each league and for each season.
for match, entropy in zip(filteredMatches, matchEntropies):
        if retVal.get(match[1]) is None:
            # this league not yet added in the hashmap
            retVal[match[1]] = dict()
            countDict[match[1]] = dict()
        retVal[match[1]][match[3]] = retVal[match[1]].get(match[3],0) + entropy
        countDict[match[1]][match[3]] = countDict[match[1]].get(match[3],0) + 1
Using this mean entropy value we were able to determine which league is the most predictable.

As a next step we also decomposed the data obtained in the previous step and came up with mean entropy for each team across each league.
This helped us to determine how the teams performed across leagues and how predictable was the performance of the teams.




--------------------------------------------------------------------------------------------------------------------------------
Player Attributes and Statistics

One of the interesting thing in sports is to compare evolution of players across time. For this purpose we filtered out the top players
based on the overall rating and sorted them by decreasing order of rating. Then for each of the player attribute records available
we found out the mean of the overall_rating column for that player across all the available years. Using this data we can find out 
the way the players have changed across years and how their ratings have changed.
# sort players by current rating and take only top 10 players
sortedByRating = sorted(players, key = lambda x  : x[1],reverse=True)[:10]
for player in sortedByRating:
# for each player get all ratings available:
    for row in Database().execute('select date,overall_rating from Player_Attributes where player_api_id is '+str(x)):
        playerMap[row[0].split('-')[0]].append(row[1])
# finally take mean for each player
for k,v in playerMap.items():
            retVal[playerName][k]=np.mean(v)

Also , one more common assumption is that usually the players who play at the common position have similar attributes. To verify this
we took the data from the players table and decided to take the numerical attributes and run PCA on that. We set the number of 
components to two as we wanted to plot the data on a 2-D plot. From the plot we can clearly observe that similar kind of players
have common components and we can observer clusters on the plot. 
pca = PCA(n_components=2,random_state=0).fit_transform(temp)
# fit pca on the on the filtered data obtained from the players table.
comp1 = pca[:,0]
comp2 = pca[:,1]
# comp1 and comp2 are the first and second pca component vectors respectively.
data = []
for a,b,c in zip(comp1,comp2,namesRating):
    data.append([a,b,c[0],c[1]])
data = [row for row in data if row[3]>80]
# Get only the players with rating more than 80.
data.sort(key = lambda x: x[3],reverse=True)
# sort the players by reverse order of rating.


For establishing the link between the leagues and the players, we had to do extensive data parsing from the database.First we had 
to find out all the leagues available in the database and then we had to iterate over all the matches in the database and for all the players involved in the match, we added the entry for the corresponding
league. Then for each of the leagues we had to create multiple links and nodes. Each node had the data for one player with the corresponding group involved
and the link had the data pertaining to source and destination of the players.

myMap = dict()
myMap["teams"] = []
for league in leagues:
    myMap["teams"].append(league[2])
    leagueNames.append(league[2])

myMap["data"] = dict()
for t in leagueNames:
    myMap["data"][t] = dict()
    myMap["data"][t]["nodes"] = []
    myMap["data"][t]["links"] = []